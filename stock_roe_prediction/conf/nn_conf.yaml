# basic feedforward neural network
fnn:
  # parameters
  learning_rate: 0.1
  num_steps: 500
  batch_size: 128
  epoch: 3
  display_step: 100
  dropout: 0.7

  # network paras
  layers: [300, 256, 256]
  num_input: 784 # MNIST data input (img shape: 28*28)
  n_hidden_1: 256 # 1st layer number of neurons
  n_hidden_2: 256 # 2nd layer number of neurons
  num_classes: 10 # MNIST total classes (0-9 digits)

# convolution neural network
cnn:
  # parameters
  learning_rate: 0.001
  num_steps: 200
  batch_size: 128
  epoch: 1
  display_step: 10
  dropout: 1.0

  # network paras
  layers: [784, 32, 64, 1024]
  num_input: 784 # MNIST data input (img shape: 28*28)
  n_hidden_1: 32 # 1st layer number of neurons
  n_hidden_2: 64 # 2nd layer number of neurons
  n_hidden_3: 1024 # 3rd layer number of neurons
  num_classes: 10 # MNIST total classes (0-9 digits)

# long short term memory
lstm:

# bidirectional lstm
bilstm:

# gated recurrent unit
gru:

in:
  data_path: ../data/ubiquant-market-prediction
  train_sample_size: 3141410
  test_sample_size: 200000

out:
  model_path: ../out
  dump_path: ../out

cnn_in:
  data_path: ../data/mnist
  train_sample_size: 25600
  test_sample_size: 10000